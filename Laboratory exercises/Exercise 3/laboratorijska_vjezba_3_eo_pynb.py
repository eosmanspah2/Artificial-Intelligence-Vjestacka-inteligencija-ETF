# -*- coding: utf-8 -*-
"""Laboratorijska vjezba 3 - EO.pynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZzrWbsTqRfzHNY_dMHASMip_MC1tzV0_

#Pokretanje primjera iz uvodnog dijela laboratorijske vježbe

Na prvoj laboratorijskoj vježbi iz neuronskih mreža, studenti se upoznaju sa problemom klasifikacije, kao jednim od
najčešćih problema iz prakse. Kroz zadatke, studenti rješavaju jednostavne probleme klasifikacije nad tekstualnim
ulaznim podacima, koristeći Keras razvojni okvir.

Prikazivanje osnovnih informacija o skupu podataka poput minimalne vrijednosti, maksimalne vrijednosti, srednje vrijednosti,
standardne devijacije, i tako dalje.
"""

import pandas as pd
data = pd.read_csv('dataset.csv')
data.describe()

"""Pandas modul omogućava i crtanje histograma za svaki od atributa:"""

import pandas as pd
data = pd.read_csv('dataset.csv')
data.hist()

"""Primjer vršenja normalizacije"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

#pripremanje testnih podataka
X, Y = np.arange(10).reshape((5, 2)), range(5)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

#Normalizacija
scaler = MinMaxScaler().fit(x_train)
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

x_train, x_test

"""Primjer vršenja standardizacije"""

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

#pripremanje testnih podataka
X, Y = np.arange(10).reshape((5, 2)), range(5)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

#Standardizacija
scaler = StandardScaler().fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

x_train, x_test

"""Primjer za model koji bi mogao poslužiti za binarnu klasifikaciju:"""

from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(8, activation='relu', input_shape=(4000,)))
model.add(layers.Dense(8, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model

"""Postavljanje funckije gubitka, optimizatora kao i metrike koja će se pratiti na modelu"""

#Adam optimizator sa podrazumijevanim postavkama
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

#eksplicitno podesavanje istog optimizatora
'''from tensorflow import keras
opt = keras.optimizers.Adam(learning_rate=0.01)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])'''

"""#Zadatak 1 - Binarna klasifikacija - Klasifikacija vina

a) Učitati podatke za crno i bijelo vino koji se nalaze u CSV datotekama winequality-red.csv i winequality-white.csv
u varijable red i white respektivno. Pri ovome postaviti parametar separator da bude znak tačka-zarez
(;). U odgovarajućim DataFrame objektima dodati novu kolonu label koja će imati vrijednost 0 za podatke
bijelog vina, a vrijednost 1 za podatke crnog vina. Nakon ovoga spojiti ih u jedan DataFrame objekat wines.
"""

import pandas as pd
import numpy as np

#ucitavanje podataka, kao i postavljanje separatora
red = pd.read_csv("winequality-red.csv",sep=";")
white = pd.read_csv("winequality-white.csv",sep=";")

#dodavanje kolone "label", gdje je crvenom vinu label = 1, a bijelom = 0
red["label"] = 1
white["label"] = 0

#spajanje u jedan DataFrame objekat
wines = pd.concat([white,red],ignore_index=True)
wines

"""b) Izvršiti prikaz osnovnih podataka spojenog skupa podataka korištenjem **describe** metode te nacrtati histograme korištenjem **hist** metode. Šta možete zaključiti o podacima?"""

wines.describe()

wines.hist(figsize=(15,20))

"""c) Iz wines izdvojiti X - karakteristike i y - labele. Zatim korištenjem funkcije train_test_split podijeliti
podatke na one za treniranje i one za testiranje pri čemu 20% podataka trebaju biti podaci za testiranje;
"""

#izdvoji/pripremi/razvrstaj podatke za train i test split
x = wines.drop("label",axis=1)
y = wines["label"]

#razdvajanje podataka na skupove za treniranje i za testiranje
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""d) Formirati sekvencijalni Keras model koji će imati 2 Dense sloja sa po 8 neurona i relu aktivacijskom
funkcijom. Prvom sloju kao input_shape parametar proslijediti vrijednost (12,) s obzirom na to da skup
podataka ima 12 značajki. Treći sloj, koji je u ovom slučaju izlazni sloj, postaviti da također bude Dense, ali
sa samo jednim neuronom;
"""

from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(8, activation = "relu", input_shape=(12,)))
model.add(layers.Dense(8, activation = "relu"))
model.add(layers.Dense(1, activation = "sigmoid"))

"""e) Kompajlirati model tako da koristi adam optimizator, za funkciju gubitka koristiti binary_crossentropy,
a kao metriku odabrati accuracy;
"""

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

"""f) Model istrenirati na 20 epoha, sa veličinom batch-a 16."""

history = model.fit(x_train, y_train, epochs=20, batch_size=16, validation_split=0.2)

from matplotlib import pyplot as plt
acc = history.history['accuracy']
loss_values = history.history['loss']
val_loss_values = history.history['val_loss']
epochs = range(1, len(acc) + 1)
plt.plot(epochs, loss_values, 'bo', label='Training loss')
plt.plot(epochs, val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

"""g) Ponoviti postupak, no ovaj put prije treniranja izvršiti standardizaciju, odnosno skaliranje atributa korištenjem
StandardScaler objekat iz sklearn.preprocessing modula. Kolika je sada tačnost nakon treniranja?
Uporediti rezultate sa onim bez skaliranja
"""

red = pd.read_csv("winequality-red.csv",sep=";")
white = pd.read_csv("winequality-white.csv",sep=";")
X = wines.drop("label",axis=1)
y = wines["label"]
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.2, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.2)

from matplotlib import pyplot as plt
acc = history.history['accuracy']
loss_values = history.history['loss']
val_loss_values = history.history['val_loss']
epochs = range(1, len(acc) + 1)
plt.plot(epochs, loss_values, 'bo', label='Training loss')
plt.plot(epochs, val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

"""h) Model evaluirati nad testnim skupom podataka. Kolika je postignuta tačnost modela?"""

results = model.evaluate(x_test, y_test)
print("Postignuta je tacnost: ",results[1])