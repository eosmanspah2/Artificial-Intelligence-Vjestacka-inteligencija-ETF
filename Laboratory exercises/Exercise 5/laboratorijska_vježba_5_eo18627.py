# -*- coding: utf-8 -*-
"""Laboratorijska vježba 5 - EO18627.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W3t5SeB6vXSYpYFXzusDBxEunoY-Zkfx

#Laboratorijska vježba 5
Cilj vježbe je upoznavanje sa drugim tipom nadziranog učenja - regresijom. Studenti se upoznaju sa razlikama pri
dizajniranju arhitekture neuronske mreže za regresiju u odnosu na klasifikaciju te rješavaju jednostavan zadatak
regresije koristeći Keras razvojni okvir.

##Zadaci za rad u laboratoriji

### Zadatak 1 - Predviđanje cijene kuća u Boston
U ovom zadatku cilj je izvršiti predikciju cijene prilikom kupovine kuće u Bostonu na bazi podataka iz 1970. godine.
Za potrebe vježbe koristiti će se historijski podaci, a oni uključuju informacije kao što je nivo kriminala u regiji,
lokalni porez, itd. Ciljne (eng. target) vrijednosti su izražene u hiljadama dolara.

a) Učitati The Boston Housing Price skup podataka. Skup podataka je dio Keras biblioteke te se može učitati
sljedećim kodom:
"""

from keras.datasets import boston_housing
(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()

"""b) Koji je oblik podataka za treniranje, a koji za testiranje? Koliko ima ukupno atributa (značajki)?"""

print("Oblik podataka za treniranje je ",train_data.shape)
print("Oblik podataka za testiranje je ",test_data.shape)
print("Ukupno atributa (znacajki) je ", train_data.shape[1])

"""c) Koji je opseg vrijednosti (min i max ) za svaki atribut u skupu podataka? A koji je opseg vrijednosti za ciljne
(eng. target) vrijednosti?
"""

import pandas as pd
data_frame_train=pd.DataFrame(train_data)
data_frame_test=pd.DataFrame(test_data)
data_frame_targets_train=pd.DataFrame(train_targets)
data_frame_targets_test=pd.DataFrame(test_targets)
data_frame=pd.concat([data_frame_train, data_frame_test,], axis=0)
data_frame_targets=pd.concat([data_frame_targets_train, data_frame_targets_test,], axis=1)

print("Opseg vrijednosti za svaki atribut u skupu podataka: ")
data_frame.describe()

print("Opseg vrijednosti za ciljne (eng.target) vrijednosti: ")
data_frame_targets.describe()

"""d) S obzirom da podaci zauzimaju široke spektre vrijednosti, izvršiti skaliranje korištenjem MinMaxScaler-a.
Obavezno povesti računa da se parametri scaler-a za skaliranje izračunaju nad trening skupom podataka, a
da se skaliranje izvrši i nad trening i nad test skupom.
"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler().fit(train_data)
train_data = scaler.fit_transform(train_data)
test_data = scaler.fit_transform(test_data)

"""e) Napisati pomoćnu funkciju def model_mreze() koja će vraćati model mreže (return model) opisan u
nastavku. Model treba da ima 2 skrivena Dense sloja sa po 64 neurona sa relu aktivacijskim funkcijama.
Dimenzije ulaznog sloja odrediti na osnovu broja atributa skupa podataka. Treći, koji je i posljednji sloj, treba
imati samo jedan neuron i ne treba imati aktivacijsku funkciju.
"""

from keras import models
from keras import layers
def model_mreze():
  n=train_data.shape[1]
  model = models.Sequential()
  model.add(layers.Dense(64, activation='relu', input_shape=(n,)))
  model.add(layers.Dense(64, activation='relu'))
  model.add(layers.Dense(1))
  return model

"""f) Kompajlirati model da koristi mse funkciju gubitka, adam optimizator i mae metriku. S obzirom da su ciljne
vijednosti izražene u hiljadama dolara, metrika MAE govori koliko model griješi u hiljadama dolara. Na primjer,
ukoliko je vrijednost MAE = 4.2, to znači da predviđanja modela odstupaju u prosjeku za $4200;
"""

model=model_mreze()
model.compile(optimizer='adam',loss='mse',metrics=['mae'])

"""g) Izvršiti treniranje modela na 100 epoha, sa veličinom batch-a jednakoj 1. Koristiti 10% trening skupa za
validaciju. Kolika je postignuta vrijednost funkcije gubitka na kraju treniranja, a kolika je vrijednost metrike
MAE? Grafički prikazati.
"""

history = model.fit(train_data, train_targets, epochs=100, batch_size=1, validation_split = 0.1)

import math
import matplotlib.pyplot as plt

#citanje potrebnih vrijednosti iz history objekta
acc = history.history['mae']
loss_values = history.history['loss']
val_loss_values = history.history['val_loss']
epochs = range(1, len(acc) + 1)

#pripremanje za crtanje grafa
plt.plot(epochs, loss_values, 'bo', label='Training loss')
plt.plot(epochs, val_loss_values, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
plt.clf()

#citanje potrebnih vrijednosti iz history objekta
acc_values = history.history['mae']
val_acc_values = history.history['val_mae']
plt.plot(epochs, acc_values, 'bo', label='Training mae')
plt.plot(epochs, val_acc_values, 'b', label='Validation mae')
plt.title('Training and validation mae')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

"""h) U prethodnom grafičkom prikazu problem predstavlja skala i visoka varijansa nad validacijskim skupom po-
dataka. Iz tog razloga je korisno prikazati usrednjene vrijednosti i zanemariti prvih 10 uzoraka radi visoke skale u početnim epohama. Ovakav prikaz nad validacijskim skupom podataka se može postići sljedećim kodom:
"""

def smooth_curve(points, factor=0.9):
  smoothed_points = []
  for point in points:
    if smoothed_points:
       previous = smoothed_points[-1]
       smoothed_points.append(previous * factor + point * (1 - factor))
    else:
        smoothed_points.append(point)
  return smoothed_points
mae_history = history.history['val_mae']
          
smooth_mae_history = smooth_curve(mae_history[10:])
plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)
plt.xlabel('Epochs')
plt.ylabel('Validation MAE')
plt.show()

"""i) Ponovo definisati model i istrenirati ga na 500 epoha. Ostale parametre ostaviti nepromijenjenim. Izvršiti
grafički prikaz usrednjenih vrijednosti kao u prethodnom zadatku. Uporediti ova dva grafička prikaza. Šta se
može zaključiti iz ovih grafika?
"""

model=model_mreze()
model.compile(optimizer='adam',loss='mse',metrics=['mae'])

#stavljamo treniranje na 500 epoha
history = model.fit(train_data, train_targets, epochs=500, batch_size=1, validation_split = 0.1)

def smooth_curve(points, factor=0.9):
  smoothed_points = []
  for point in points:
    if smoothed_points:
       previous = smoothed_points[-1]
       smoothed_points.append(previous * factor + point * (1 - factor))
    else:
        smoothed_points.append(point)
  return smoothed_points
mae_history = history.history['val_mae']
          
smooth_mae_history = smooth_curve(mae_history[10:])
plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)
plt.xlabel('Epochs')
plt.ylabel('Validation MAE')
plt.show()

"""j) Izvršiti evaluaciju modela nad testnim skupom podataka. Koja je postignuta vrijednost funkcije gubitka, a
koja vrijednost metrike MAE? Koliko prosječno u dolarima griješi model u svojim predikcijama?
"""

results = model.evaluate(test_data,test_targets)

import math
print("Funkcija gubitka: ", results[0])
print("Vrijednost metrike MAE: ", results[1])
print("Model prosječno griješi {} u dolarima".format(math.floor(1000000*results[1])/1000.0))