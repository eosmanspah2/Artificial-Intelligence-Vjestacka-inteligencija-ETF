# -*- coding: utf-8 -*-
"""Laboratorijska vježba 2 - Emir Osmanspahić 18627.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/166SFTzqfc0AFqxZJfG1Px05ZxJTLPPX_

#Uvodni primjeri za upoznavanje sa novim funkcionalnostima i bibliotekama

## Pandas
"""

import pandas as pd # ucitaj Pandas
import numpy as np # ucitaj NumPy
data = pd.read_csv('dataset.csv') # ucitaj podatke
data

data.head() #uzimamo prvih 5 elemenata po defaultu

data.tail(2) #uzimamo zadnja dva reda

data_transponovano = data.T
data_transponovano #transponovanje podataka

data["Indeks"] #odabir jedne kolone

data[3:8] #uzimanje podsekvence redova

# nadji indeks studenta u 5. redu
data.loc[5, 'Indeks']

# svi studenti koji imaju ukupno preko 43 boda
data.loc[data['UKUPNO'] > 43]

# izlistaj indeks i prisustvo za trećeg,četvrtog i petog studenta
data.loc[2:4, ['Indeks', 'Prisustvo']]

df = pd.DataFrame(np.arange(25).reshape(5,5),
index=[5,4,3,2,1],
columns=['x', 'y', 'z', 'v', 'i'])

df

# loc radi sa kljucem (index) reda,
# i sa nazivima kolona
df.loc[1, 'x'] #uzimamo element sto se nalazi u redu sa id 1 i koloni x

# iloc radi isključivo sa stvarnim (integer) indeksima
# (kao standardne matrice)
df.iloc[1, 0] #iloc posmatra dataframe objekat kao stvarnu matricu, uzimamo element na indexu [1][0]

data.replace('/', np.nan, inplace=True)
data.head() # svaka pojava / zamijenjena sa NaN

data.head()

data.drop([2, 3, 4], inplace=True) # izbaci redove na indeksima 2, 3, i 4
data.head()

# izbaci kolonu ispit2
data.drop(columns=['Ispit2'], inplace=True)
data.head()

data

"""#Primjeri koristenja Scikit-Learn (sklearn) biblioteke"""

data = pd.read_csv('dataset.csv') # ucitaj podatke
data.replace('/', np.nan, inplace=True)
data

from sklearn.impute import SimpleImputer
si = SimpleImputer(strategy='mean')
print('Prije zamjene: ')
print(data.loc[:5, 'Ispit2'])
data.loc[:, 'Ispit2'] = si.fit_transform(data.loc[:, 'Ispit2'].values.reshape(-1,1))
print('Nakon zamjene: ')
print(data.loc[:5, 'Ispit2'])

from sklearn.preprocessing import scale
data['Ispit2'] = scale(data['Ispit2']) # Z score
data.loc[:5, 'Ispit2']

from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()
data['Ispit2'] = mm.fit_transform(data['Ispit2'].values.reshape(-1,1))
data.loc[:5, 'Ispit2']

import numpy as np
from sklearn.model_selection import train_test_split

X, Y = np.arange(10).reshape((5, 2)), range(5)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
test_size=0.33,
random_state=42)
X,Y

"""#Primjer koristenja Pickle datoteke"""

import pickle
import os
import numpy as np
niz = np.arange(1000000)
print("Zauzima {0} kB".format(niz.nbytes/1000))
pickle.dump(niz, open( "datoteka.p", "wb" ), protocol=pickle.HIGHEST_PROTOCOL)
velicina = os.path.getsize('datoteka.p')
print("Datoteka zauzima {0} kB".format(velicina/1000))
niz2 = pickle.load(open("datoteka.p", 'rb'))
if (niz2 == niz).all():
  print("Nizovi su identicni!")

"""# 3 Zadaci za rad u laboratoriji
Predviđeno je da se svi zadaci u nastavku rade u sklopu Jupyter Notebook okruženja. Svaki podzadatak treba biti
zasebna Jupyter ćelija.

##Zadatak 1 - Obrada podataka kroz Pandas
Uz vježbu ste dobili datoteku izvjestaj.csv. Potrebno je, koristeći Pandas:

a) Učitati datoteku kao Pandas DataFrame, te prikazati prvih 5 i posljednjih 10 unosa u istoj
"""

#Priprema podataka za prvi zadatak
import numpy as np # ucitaj NumPy
import pandas as pd # ucitaj Pandas

data = pd.read_csv('dataset.csv') # ucitaj podatke

data.head() #prvih 5
data.tail(10) #zadnjih 10

"""b) Ispisati samo podatke vezane za redovne parcijalne ispite (kolone Ispit1 i Ispit2 );"""

data.loc[:, ['Ispit1', 'Ispit2']]

"""c) Ispisati sve studente koji su izgubili prisustvo"""

data.loc[data['Prisustvo'] == 0]

"""c) Ispisati indeks, ukupne bodove, i ocjenu, za sve studente koji su upisali ocjenu 8 ili više;"""

data.loc[data['Ocjena'] >= '8', ['Indeks', 'UKUPNO', 'Ocjena']]

"""e) Sve nedostajuće vrijednosti (označene sa simbolom /) zamijeniti sa vrijednošću np.nan"""

data.replace('/', np.nan, inplace=True)
data

"""f) Iz skupa podataka odbaciti sve studente koji nemaju upisanu ocjenu"""

data.dropna(subset=['Ocjena'])

"""g) Kreirati novu kolonu Ispit1_final u koju ćete za svakog studenta upisati onaj rezultat ispita koji je bolji (na
primjer, ako je student bolje uradio popravni ispit, onda tu pišete bodove sa popravnog, a u protivnom sa
redovnog);
"""

ispitiRedovni = data["Ispit1"]
ispitiPopravni = data["Ispit1_popravni"]
ispitiFinal = []
for i in range(0,len(ispitiRedovni)):
  if(isinstance(ispitiRedovni[i],str) != True and isinstance(ispitiPopravni[i],str)!=True): #Ako su oba nan, svejedno
    ispitiFinal.append(ispitiRedovni[i])
  elif (isinstance(ispitiRedovni[i],str) != True ): #Ako nije izlazio na redovni, automatski upisujemo popravni
    ispitiFinal.append(ispitiPopravni[i])
  elif (isinstance(ispitiPopravni[i],str) != True ): #Ako nije izlazio na popravni, automatski upisujemo redovni
    ispitiFinal.append(ispitiRedovni[i])
  elif (float(ispitiRedovni[i])>=float(ispitiPopravni[i])): #Ako je vise imao na redovnom ili isto, upisujemo redovni
    ispitiFinal.append(ispitiRedovni[i])
  else: #U ostalim slucajevima upisujemo popravni
    ispitiFinal.append(ispitiPopravni[i])

data['Ispit1_final']=ispitiFinal
data

"""h) Ponoviti postupak za Ispit2 """

ispitiRedovni = data["Ispit2"]
ispitiPopravni = data["Ispit2_popravni"]
ispitiFinal = []
for i in range(0,len(ispitiRedovni)):
  if(isinstance(ispitiRedovni[i],str) != True and isinstance(ispitiPopravni[i],str)!=True): #Ako su oba nan, svejedno
    ispitiFinal.append(ispitiRedovni[i])
  elif (isinstance(ispitiRedovni[i],str) != True ): #Ako nije izlazio na redovni, automatski upisujemo popravni
    ispitiFinal.append(ispitiPopravni[i])
  elif (isinstance(ispitiPopravni[i],str) != True ): #Ako nije izlazio na popravni, automatski upisujemo redovni
    ispitiFinal.append(ispitiRedovni[i])
  elif (float(ispitiRedovni[i])>=float(ispitiPopravni[i])): #Ako je vise imao na redovnom ili isto, upisujemo redovni
    ispitiFinal.append(ispitiRedovni[i])
  else: #U ostalim slucajevima upisujemo popravni
    ispitiFinal.append(ispitiPopravni[i])

data['Ispit2_final']=ispitiFinal
data

"""i) Odbaciti četiri stare kolone za ispite"""

data.drop(columns=['Ispit1','Ispit2','Ispit1_popravni', 'Ispit2_popravni'], inplace=True)
data

"""j) Skup podataka sačuvati kao CSV datoteku pod nazivom izvjestaj_modificirano.csv. Koristiti znak tačka-zarez
kao separator
"""

data.to_csv('izvjestaj_modificirano.csv',index=False)

"""k) Skup podataka sačuvati kao Pickle datoteku pod nazivom izvjestaj_modificirano_pickle.p."""

import pickle
pickle.dump(data, open( "izvjestaj_modificirano.p", "wb" ), protocol=pickle.HIGHEST_PROTOCOL)

"""#Zadatak 2 - Normalizacija podataka pomoću Sklearn

a) Učitati datoteku izvjestaj.csv kao Pandas DataFrame;
"""

import pandas as pd
import numpy as np # ucitaj NumPy
data = pd.read_csv('dataset.csv') # ucitaj podatke
data.replace('/', np.nan, inplace=True)
data

"""b) Za kolone koje predstavljaju redovne ispite, izvršiti zamjenu nedostajućih vrijednosti strategijom median"""

from sklearn.impute import SimpleImputer
si = SimpleImputer(strategy='median')

print('Prije zamjene: ')
print(data.loc[:5, 'Ispit1'])
print(data.loc[:5, 'Ispit2'])
data.loc[:, 'Ispit1'] = si.fit_transform(data.loc[:, 'Ispit1'].values.reshape(-1,1))
data.loc[:, 'Ispit2'] = si.fit_transform(data.loc[:, 'Ispit2'].values.reshape(-1,1))
print('Nakon zamjene: ')
print(data.loc[:5, 'Ispit1'])
print(data.loc[:5, 'Ispit2'])

"""c) Za kolone koje predstavljaju popravne ispite, izvršiti zamjenu nedostajućih vrijednosti pomoću strategije mean"""

from sklearn.impute import SimpleImputer
si = SimpleImputer(strategy='mean')

print('Prije zamjene: ')
print(data.loc[:5, 'Ispit1_popravni'])
print(data.loc[:5, 'Ispit2_popravni'])
data.loc[:, 'Ispit1_popravni'] = si.fit_transform(data.loc[:, 'Ispit1_popravni'].values.reshape(-1,1))
data.loc[:, 'Ispit2_popravni'] = si.fit_transform(data.loc[:, 'Ispit2_popravni'].values.reshape(-1,1))
print('Nakon zamjene: ')
print(data.loc[:5, 'Ispit1_popravni'])
print(data.loc[:5, 'Ispit2_popravni'])

"""d) Izvršiti Z-score normalizaciju vrijednosti za redovne parcijalne ispite"""

from sklearn.preprocessing import scale
print("Ispit 1 prije normalizacije")
print(data.loc[:5,'Ispit1'])
data['Ispit1'] = scale(data['Ispit1']) 
print("Ispit 1 poslije normalizacije")
print(data.loc[:5, 'Ispit1'])

print("Ispit 2 prije normalizacije")
print(data.loc[:5,'Ispit2'])
data['Ispit2'] = scale(data['Ispit2']) 
print("Ispit 2 poslije normalizacije")
print(data.loc[:5, 'Ispit2'])

"""e) Izvršiti MinMax normalizaciju vrijednosti za popravne parcijalne ispite"""

from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()

print("Ispit1_popravni prije normalizacije")
print(data.loc[:5,'Ispit1_popravni'])
data['Ispit1_popravni'] = mm.fit_transform(data['Ispit1_popravni'].values.reshape(-1,1))
print("Ispit1_popravni poslije normalizacije")
print(data.loc[:5, 'Ispit1_popravni'])

print("Ispit2_popravni prije normalizacije")
print(data.loc[:5,'Ispit2_popravni'])
data['Ispit2_popravni'] = mm.fit_transform(data['Ispit2_popravni'].values.reshape(-1,1))
print("Ispit2_popravni poslije normalizacije")
print(data.loc[:5, 'Ispit2_popravni'])

"""f) Sve ostale nedostajuće vrijednosti u skupu podataka zamijeniti sa nulama"""

data.replace(np.nan, '0', inplace=True)
data

"""g) Izdvojiti kolonu Ocjena u posebnu varijablu, na način da sada u originalnom skupu podataka ta kolona više
ne postoji
"""

print("Prije izdvajanja kolone Ocjena: ")
print(data)
ocjene = data.pop("Ocjena")
print("Poslije izdvajanja kolone Ocjena: ")
print(data)
print("Ocjene: ")
print(ocjene)

"""h) Konvertovati obje varijable (originalni skup podataka bez kolone Ocjena, kao i posebnu kolonu Ocjena) u
NumPy nizove
"""

print("Prije konvertovanja: ")
print(data)
print(ocjene)
print("Poslije konvertovanja: ")
data = data.to_numpy()
ocjene = ocjene.to_numpy()
print(data)
print(ocjene)

"""i) Ukoliko pretpostavimo da NumPy niz sa ocjenama predstavlja labele, a niz sa ostalim kolonama atribute
(značajke), izvršiti podjelu na trening i testni skup podataka, pri čemu za testni skup treba uzeti 20% podataka.
"""

import numpy as np
from sklearn.model_selection import train_test_split


data_train, data_test, ocjene_train, ocjene_test = train_test_split(data, ocjene, test_size=0.2, random_state=42)
print("Data train: ")
print(data_train)
print("Data test: ")
print(data_test)
print("Ocjene train: ")
print(ocjene_train)
print("Ocjene test: ")
print(ocjene_test)

"""#Zadatak 3 - Klasični algoritam mašinskog učenja

U ovom zadatku, upoznat ćemo se sa primjenom Sklearn biblioteke u klasičnim algoritimma mašinskog učenja.
Konkretno, radit će se klasifikacija cvijeta iris na tri različite vrste (prikazane na slici u postavci), i to:
• Setosa;
• Versicolour;
• Virginica;

Algoritam će prvo na osnovu postojećeg skupa podataka, koji sadrži značajke i labele, naučiti kako koja značajka
djeluje samu vrstu cvijeta, te će biti u stanju da za novi (neviđeni) podatak pretpostavi tačnu klasu kojoj cvijet
pripada.

a) Sam skup podataka dolazi spreman uz Sklearn, te ga je potrebno učitati:
"""

from sklearn.datasets import load_iris

iris = load_iris()
X = iris.data
y = iris.target

feature_names = iris.feature_names
target_names = iris.target_names

print("Nazivi znacajki:", feature_names)
print("Nazivi labela:", target_names)
print("\nPrvih 5 redova X:\n", X[:5])

"""b) Sljedeći korak jeste dijeljenje skupa podataka na dva dijela - trening i testni skup. Trening skup se koristi
kako bi algoritam naučio uzorke ponašanja, dok testni skup predstavlja nove podatke, na osnovu kojih se vrši
evaluacija algoritma (to jeste evaluacija naučenog).
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1 )

print("X_train: ")
print(X_train.shape)
print("x_test: ")
print(X_test.shape)

print("Y_train: ")
print(y_train.shape)
print("Y_test: ")
print(y_test.shape)

"""c) Sada je vrijeme da se primijeni odgovarajući algoritam. U ovom primjeru, koristit ćemo k-NN (eng. k-nearest
neighbours). Ovaj algoritam je izuzetno jednostavan, te klasifikaciju vrši na način da svaki podatak mapira kao
n-dimenzionalnu tačku. Klasa novog podatka se zatim određuje na osnovu k najbližih tačaka u tom prostoru.
Uzima se ona klasa koja se pojavljuje najčešće u k najbližih susjeda. Ovaj algoritam je već implementiran u
sklopu Sklearn, pa se može jednostavno pozvati:
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

classifier_knn = KNeighborsClassifier(n_neighbors = 3)

classifier_knn.fit(X_train, y_train)

"""d) Konačno, potrebno je algoritam primijeniti nad testnim skupom, kako bi se odredila uspješnost. U tu svrhu,
koristi se isječak koda kao što slijedi:
"""

y_pred = classifier_knn.predict(X_test)

print("Tacnost:", metrics.accuracy_score(y_test, y_pred))

"""e) Ponovite ovaj proces za nekoliko različitih vrijednosti k."""

#k = 4
classifier_knn = KNeighborsClassifier(n_neighbors = 4)
classifier_knn.fit(X_train, y_train)
y_pred = classifier_knn.predict(X_test)
print("Tacnost:", metrics.accuracy_score(y_test, y_pred))

#k = 44
classifier_knn = KNeighborsClassifier(n_neighbors = 44)
classifier_knn.fit(X_train, y_train)
y_pred = classifier_knn.predict(X_test)
print("Tacnost:", metrics.accuracy_score(y_test, y_pred))

#k = 105
classifier_knn = KNeighborsClassifier(n_neighbors = 105)
classifier_knn.fit(X_train, y_train)
y_pred = classifier_knn.predict(X_test)
print("Tacnost:", metrics.accuracy_score(y_test, y_pred))

"""#Zadatak 4 - Duboko učenje

Duboko učenje ćemo demonstrirati na primjeru klasifikacije rukom pisanih cifara. Koristit ćemo MNIST skup podataka, koji sadrži 70000 slika u nijansama sive boje (eng. grayscale) dimenzija 28 × 28 podijeljenih u 10 različitih
klasa (za svaku cifru po jedna).

a) Učitavanje podataka je prvi korak. Keras ovaj skup podataka ima spreman, te je on unaprijed podijeljen na
trening i test skup.
"""

from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print("X_train: ")
print(x_train.shape)
print("x_test: ")
print(x_test.shape)

print("Y_train: ")
print(y_train.shape)
print("Y_test: ")
print(y_test.shape)

"""Kako bi se ove slike mogle poslati u neuralnu mrežu, potrebno je iste prvo pretvoriti u brojeve u pokretnom
zarezu, te ih svesti na opseg između 0 i 1. Obzirom da pikseli grayscale slika uzimaju vrijednosti između 0 i
255, svođenje na traženi opseg se može uraditi prostim dijeljenjm sa 255. Sljedeći isječak koda demonstrira
ovaj korak:
"""

train_images = x_train.reshape((x_train.shape[0], 28 * 28))
train_images = train_images.astype('float32') / 255

test_images = x_test.reshape((x_test.shape[0], 28*28))
test_images = test_images.astype('float32') / 255

"""c) Nakon što su podaci spremni, može se napraviti jednostavan model duboke neuralne mreže. U tu svrhu, koristi
se Keras. Prije svega je potrebno kreirati sam model, nakon čega se na isti dodaju slojevi različitog tipa:
"""

from keras import models
from keras import layers

network = models.Sequential()
network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))
network.add(layers.Dense(10, activation='softmax'))

"""Model koji smo upravo kreirali ima dva sloja - to je
potpuno dovoljno za ovaj jednostavan zadatak, međutim u praksi modeli znaju imati dosta više slojeva - tada se kaže da su modeli duboki. Sloj se može zamisliti kao filter za podatke. Podaci uđu u sloj, te se na izlazu dobijaju podaci u nešto korisnijoj formi. Slojevi vrše ekstrakciju reprezentacije iz podataka koji se dovedu na
njihov ulaz - pri tome se uvijek nadamo da se tu radi o korisnim reprezentacijama. Većina dubokog učenja
se sastoji od nadovezivanja različitih jednostavnih slojeva koji će progresivno raditi filtriranje podataka (data
distilation). Model se može zamisliti kao sito za podatke - sito napravljeno od više filtera/slojeva. Slojevi koji
se koriste u ovom modelu su dense slojevi, koji se još nazivaju i potpuno povezani slojevi. Pri tome, drugi
(posljednji) sloj je softmax sloj sa 10 neurona, što znači da će on vratiti niz od 10 vjerovatnoća (čija će suma
biti 1). Svaka vrijednost u tom nizu označava vjerovatnoću kojom trenutna slika pripada odgovarajućoj cifri.
Na primjer, ukoliko je na prvom mjestu ovog izlaznog niza broj 0.35, onda je šansa da se radi o cifri nula
jednaka 35%.

d) Kada je model definisan, on se mora pripremiti za treniranje. Kako bi to bilo moguće, model je prvo potrebno
kompajlirati. Kompajliranje modela se sastoji od odabira tri parametra:

  • Funkcije gubitka (eng. loss function) - Označava kako neuralna
  mreža može mjeriti svoje performanse
  nad trening skupom, te se na osnovu nje prilagođava prilikom 
  procesa  treniranja

  • Optimizator (eng. optimizer ) - Mehanizam na osnovu kojeg se      
  neuralna mreža aktualizira;
  
  • Metrike koje treba pratiti prilikom treniranja i testiranja - U 
  ovom slučaju nas zanima samo tačnost (eng.
  accuracy). Za različite zadatke dubokog učenja su razvijene i 
  različite metrike uspjeha.

  Kompajliranje modela se vrši pomoću sljedećeg isječka koda:
"""

network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

"""e) U prethodnom koraku smo rekli da je izlaz iz neuralne mreže zapravo niz od 10 elemenata. Shodno tome,
moramo labele prilagoditi izlazu, na način da izvršimo one-hot kodiranje istih. Kodiranje podrazumijeva
pretvaranje labele iz konkretne vrijednosti u niz od n elemenata gdje su svi elementi nula, osim elementa na
indeksu koji odgovara tačnoj klasi. Primjer one-hot kodiranja je dat u nastavku:

3 → [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]

Kako bi se ovo postiglo u Python-u, može se koristiti gotova funkcija koju pruža Keras, kao što je prikazano u
nastavku:
"""

from tensorflow.keras.utils import to_categorical

#greska from keras.utils import to_categorical

train_labels = to_categorical(y_train)
test_labels = to_categorical(y_test)

"""f) Sada je sve spremno da se mreža trenira. Treniranje je izuzetno jednostavno, te se obavlja pomoću jedne linije
koda:
"""

network.fit(train_images, train_labels, epochs=5, batch_size=128)

"""g) Nakon što se treniranje završi, može se izvršiti evaluacija nad testnim skupom podataka:

"""

test_loss, test_acc = network.evaluate(test_images, test_labels)
print('Tacnost za testni skup:', test_acc)